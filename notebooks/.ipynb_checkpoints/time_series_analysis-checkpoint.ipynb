{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis\n",
    "Before we start that we need to make sure all data is preprocessed and all columns have the right name!\n",
    "Of course as usuall we start by importing relevant libraries packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RandomForestRegressora' from 'sklearn.ensemble' (c:\\users\\rafaa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_pipeline\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressora\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_regression\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#tensorflow or pytorch!\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'RandomForestRegressora' from 'sklearn.ensemble' (c:\\users\\rafaa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "#tensorflow or pytorch!\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.set()\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"expand_frame_repr\", False)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(\"../features/train_features.csv\")\n",
    "test_features = pd.read_csv(\"../features/test_features.csv\")\n",
    "train_sales = pd.read_csv(\"../features/train_sales.csv\")\n",
    "train_customers = pd.read_csv(\"../features/train_customers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, all our features are numeric. Since our problem is a regression problem, we can narrow down the list of algorithms we will use for modelling. Random forests Regressor will make for a good start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241m.\u001b[39mLGBMRegressor\n\u001b[0;32m      2\u001b[0m feature_columns \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m train_features]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_columns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lgb' is not defined"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMRegressor\n",
    "feature_columns = [x for x in train_features]\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_columns, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature Importance\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mfeature_importances_})\n\u001b[0;32m      2\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m feature_importance\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m feature_importance\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({'Feature': feature_columns, 'Feature Importance': model.feature_importances_})\n",
    "feature_importance = feature_importance.set_index('Feature')\n",
    "feature_importance = feature_importance.sort_values(\"Feature\", ascending=True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImp(model, X , num = 20, fig_size = (40, 20)):\n",
    "    feature_imp = pd.DataFrame({'Value':model.feature_importance(),'Feature':X.columns})\n",
    "#     plt.figure(figsize=fig_size)\n",
    "#     sb.set(font_scale = 5)\n",
    "#     sb.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n",
    "#                                                         ascending=False)[0:num])\n",
    "#     plt.title('LightGBM Features (avg over folds)')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('lgbm_importances-01.png')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "arg must be a list, tuple, 1-d array, or Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [108]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_importance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\rafaa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\tools\\numeric.py:164\u001b[0m, in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    162\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([arg], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg must be a list, tuple, 1-d array, or Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     values \u001b[38;5;241m=\u001b[39m arg\n",
      "\u001b[1;31mTypeError\u001b[0m: arg must be a list, tuple, 1-d array, or Series"
     ]
    }
   ],
   "source": [
    "f = pd.to_numeric(feature_importance, downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "# regressor.fit(X_train, y_train)\n",
    "# y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "\n",
    "# print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "# print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "# print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
